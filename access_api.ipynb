{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (21.4.0)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/console.py\", line 1752, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/console.py\", line 1390, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/segment.py\", line 245, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/console.py\", line 1368, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/req_command.py\", line 148, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/self_outdated_check.py\", line 237, in pip_self_version_check\n",
      "    logger.info(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.1.2', new='23.1.2'),)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (0.27.8)\n",
      "Requirement already satisfied: tqdm in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages (from aiohttp->openai) (1.2.0)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/console.py\", line 1752, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/console.py\", line 1390, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/segment.py\", line 245, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/console.py\", line 1368, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/cli/req_command.py\", line 148, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/self_outdated_check.py\", line 237, in pip_self_version_check\n",
      "    logger.info(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1477, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"/Users/joshua.grefte/Library/Python/3.10/lib/python/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.1.2', new='23.1.2'),)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openai\n",
    "!pip3 install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "#https://www.youtube.com/watch?v=uCKH8bmPgFs&t=502s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create resource group and resource and deploy gpt4 model then use api key and endpoint value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7Qwv0Bm8qIWkBrmlrp9mhSyctD7l4\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1686657366,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Sure, here's an example:\\n\\nIncorrect code:\\n\\n```javascript\\n// server.js\\n\\nconst express = require('express');\\nconst app = express();\\n\\napp.get('/', (req, res) => {\\n  res.send('Hello World!');\\n});\\n\\napp.listen(3000, () => {\\n  console.log('Server started on port 3000');\\n});\\n```\\n\\nThe bug in this code is that the route handler for the root path (`/`) is not returning a response with the correct content type. It should be returning a JSON response, but instead it's returning a plain text response.\\n\\nHere's a unit test that will fail due to this bug:\\n\\n```javascript\\n// server.test.js\\n\\nconst request = require('supertest');\\nconst app = require('./server');\\n\\ndescribe('GET /', () => {\\n  it('should return a JSON response', async () => {\\n    const res = await request(app).get('/');\\n    expect(res.type).toBe('application/json');\\n  });\\n});\\n```\\n\\nWhen you run this test, it will fail with the following error message:\\n\\n```\\nExpected response type to be \\\"application/json\\\" but received \\\"text/html\\\"\\n```\\n\\nTo fix the bug, we need to modify the route handler to return a JSON response:\\n\\n```javascript\\n// server.js\\n\\nconst express = require('express');\\nconst app = express();\\n\\napp.get('/', (req, res) => {\\n  res.json({ message: 'Hello World!' });\\n});\\n\\napp.listen(3000, () => {\\n  console.log('Server started on port 3000');\\n});\\n\\n```\\n\\nNow when you run the test, it should pass.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 327,\n",
      "    \"prompt_tokens\": 69,\n",
      "    \"total_tokens\": 396\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "output:  Sure, here's an example:\n",
      "\n",
      "Incorrect code:\n",
      "\n",
      "```javascript\n",
      "// server.js\n",
      "\n",
      "const express = require('express');\n",
      "const app = express();\n",
      "\n",
      "app.get('/', (req, res) => {\n",
      "  res.send('Hello World!');\n",
      "});\n",
      "\n",
      "app.listen(3000, () => {\n",
      "  console.log('Server started on port 3000');\n",
      "});\n",
      "```\n",
      "\n",
      "The bug in this code is that the route handler for the root path (`/`) is not returning a response with the correct content type. It should be returning a JSON response, but instead it's returning a plain text response.\n",
      "\n",
      "Here's a unit test that will fail due to this bug:\n",
      "\n",
      "```javascript\n",
      "// server.test.js\n",
      "\n",
      "const request = require('supertest');\n",
      "const app = require('./server');\n",
      "\n",
      "describe('GET /', () => {\n",
      "  it('should return a JSON response', async () => {\n",
      "    const res = await request(app).get('/');\n",
      "    expect(res.type).toBe('application/json');\n",
      "  });\n",
      "});\n",
      "```\n",
      "\n",
      "When you run this test, it will fail with the following error message:\n",
      "\n",
      "```\n",
      "Expected response type to be \"application/json\" but received \"text/html\"\n",
      "```\n",
      "\n",
      "To fix the bug, we need to modify the route handler to return a JSON response:\n",
      "\n",
      "```javascript\n",
      "// server.js\n",
      "\n",
      "const express = require('express');\n",
      "const app = express();\n",
      "\n",
      "app.get('/', (req, res) => {\n",
      "  res.json({ message: 'Hello World!' });\n",
      "});\n",
      "\n",
      "app.listen(3000, () => {\n",
      "  console.log('Server started on port 3000');\n",
      "});\n",
      "\n",
      "```\n",
      "\n",
      "Now when you run the test, it should pass.\n",
      "--------------------------------------------------\n",
      "tokens:  {\n",
      "  \"completion_tokens\": 327,\n",
      "  \"prompt_tokens\": 69,\n",
      "  \"total_tokens\": 396\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\" \n",
    "openai.api_base = \"https://gpt4resource.openai.azure.com/\" # Your Azure OpenAI resource's endpoint value.\n",
    "openai.api_key = \"618bf90290544e54b47bcfc2dba743da\"\n",
    "\n",
    "system_message = 'Assistant is an intelligent chatbot designed to help users create programming training materials'\n",
    "user_message1 = 'Could you please provide me with incorrect code in Node.js, followed by a corresponding unit test that will fail due to the introduced bug? At the end provide the corrected code. Area of interest is web development.'\n",
    "response = openai.ChatCompletion.create(\n",
    "    #gpt-35-turbo max tokens = 4,096\n",
    "    engine=\"testdeploy\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message1}\n",
    "    ],\n",
    "    temperature = 0 # This is the degree of randomness of the model's output\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(50*'-')\n",
    "output = response['choices'][0]['message']['content']\n",
    "print('output: ', output)\n",
    "print(50*'-')\n",
    "print('tokens: ', response['usage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7Qwya3k7HGMKd5zW5muQJNDawGp0I\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1686657588,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Sure, here's an example:\\n\\nIncorrect code:\\n\\n```javascript\\n// server.js\\n\\nconst express = require('express');\\nconst app = express();\\n\\napp.get('/', (req, res) => {\\n  res.send('Hello World!');\\n});\\n\\napp.listen(3000, () => {\\n  console.log('Server started on port 3000');\\n});\\n```\\n\\nBug: The server is listening on port 3000, but the code doesn't check if the port is already in use. If the port is already in use, the server will fail to start.\\n\\nUnit test:\\n\\n```javascript\\n// server.test.js\\n\\nconst request = require('supertest');\\nconst app = require('./server');\\n\\ndescribe('GET /', () => {\\n  it('should return 200 OK', (done) => {\\n    request(app)\\n      .get('/')\\n      .expect(200, done);\\n  });\\n});\\n\\ndescribe('Server', () => {\\n  it('should start without errors', (done) => {\\n    const server = app.listen(3000, () => {\\n      server.close();\\n      done();\\n    });\\n  });\\n});\\n```\\n\\nThe second test checks if the server starts without errors by attempting to listen on port 3000. If the server fails to start, the test will fail.\\n\\nCorrected code:\\n\\n```javascript\\n// server.js\\n\\nconst express = require('express');\\nconst app = express();\\n\\napp.get('/', (req, res) => {\\n  res.send('Hello World!');\\n});\\n\\nconst server = app.listen(3000, () => {\\n  console.log('Server started on port 3000');\\n});\\n\\nserver.on('error', (err) => {\\n  console.error(`Server error: ${err}`);\\n});\\n```\\n\\nThe corrected code checks for errors when starting the server and logs them to the console.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 364,\n",
      "    \"prompt_tokens\": 69,\n",
      "    \"total_tokens\": 433\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "output:  Sure, here's an example:\n",
      "\n",
      "Incorrect code:\n",
      "\n",
      "```javascript\n",
      "// server.js\n",
      "\n",
      "const express = require('express');\n",
      "const app = express();\n",
      "\n",
      "app.get('/', (req, res) => {\n",
      "  res.send('Hello World!');\n",
      "});\n",
      "\n",
      "app.listen(3000, () => {\n",
      "  console.log('Server started on port 3000');\n",
      "});\n",
      "```\n",
      "\n",
      "Bug: The server is listening on port 3000, but the code doesn't check if the port is already in use. If the port is already in use, the server will fail to start.\n",
      "\n",
      "Unit test:\n",
      "\n",
      "```javascript\n",
      "// server.test.js\n",
      "\n",
      "const request = require('supertest');\n",
      "const app = require('./server');\n",
      "\n",
      "describe('GET /', () => {\n",
      "  it('should return 200 OK', (done) => {\n",
      "    request(app)\n",
      "      .get('/')\n",
      "      .expect(200, done);\n",
      "  });\n",
      "});\n",
      "\n",
      "describe('Server', () => {\n",
      "  it('should start without errors', (done) => {\n",
      "    const server = app.listen(3000, () => {\n",
      "      server.close();\n",
      "      done();\n",
      "    });\n",
      "  });\n",
      "});\n",
      "```\n",
      "\n",
      "The second test checks if the server starts without errors by attempting to listen on port 3000. If the server fails to start, the test will fail.\n",
      "\n",
      "Corrected code:\n",
      "\n",
      "```javascript\n",
      "// server.js\n",
      "\n",
      "const express = require('express');\n",
      "const app = express();\n",
      "\n",
      "app.get('/', (req, res) => {\n",
      "  res.send('Hello World!');\n",
      "});\n",
      "\n",
      "const server = app.listen(3000, () => {\n",
      "  console.log('Server started on port 3000');\n",
      "});\n",
      "\n",
      "server.on('error', (err) => {\n",
      "  console.error(`Server error: ${err}`);\n",
      "});\n",
      "```\n",
      "\n",
      "The corrected code checks for errors when starting the server and logs them to the console.\n",
      "--------------------------------------------------\n",
      "tokens:  {\n",
      "  \"completion_tokens\": 364,\n",
      "  \"prompt_tokens\": 69,\n",
      "  \"total_tokens\": 433\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-05-15\" \n",
    "openai.api_base = \"https://gpthackathonkainos.openai.azure.com/\" # Your Azure OpenAI resource's endpoint value.\n",
    "openai.api_key = \"58a0018ce5ce4d83833c6daa1db7ad67\"\n",
    "\n",
    "system_message = 'Assistant is an intelligent chatbot designed to help users create programming training materials'\n",
    "user_message1 = 'Could you please provide me with incorrect code in Node.js, followed by a corresponding unit test that will fail due to the introduced bug? At the end provide the corrected code. Area of interest is web development.'\n",
    "response = openai.ChatCompletion.create(\n",
    "    #gpt-35-turbo max tokens = 4,096\n",
    "    engine=\"hackathon\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message1}\n",
    "    ],\n",
    "    temperature = 0 # This is the degree of randomness of the model's output\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(50*'-')\n",
    "output = response['choices'][0]['message']['content']\n",
    "print('output: ', output)\n",
    "print(50*'-')\n",
    "print('tokens: ', response['usage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN CELL TO SAVE OUTPUT IN A TXT FILE\n",
    "import os\n",
    "\n",
    "folder_path = 'txt_outputs'\n",
    "text_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "txt_number_list = []\n",
    "for file_name in text_files:\n",
    "    txt_number = file_name[-5]\n",
    "    txt_number = int(txt_number)\n",
    "    txt_number_list.append(txt_number)\n",
    "if not txt_number_list: #check if list is empty, i.e. no txt files yet\n",
    "    new_txt_number = str(1)\n",
    "else:\n",
    "    new_txt_number = str(max(txt_number_list) + 1)\n",
    "text_file = open('txt_outputs/output' + '_' + new_txt_number + '.txt', 'w')\n",
    "text_file.write(system_message + '\\n')\n",
    "text_file.write(50*'-' + '\\n')\n",
    "text_file.write(user_message1 + '\\n')\n",
    "text_file.write(50*'-' + '\\n')\n",
    "text_file.write(output + '\\n')\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
